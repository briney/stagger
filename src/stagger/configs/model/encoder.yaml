# Model hyperparameters
d_model: 768
n_heads: 12
n_layers: 12
ffn_mult: 4.0       # expansion factor for SwiGLU
vocab_size: 21      # input AA vocab, e.g., 20 + pad/unk
codebook_size: 512  # number of structure tokens/classes
pad_id: 0

# Rotary embeddings
rope:
  base: 10000
  scaling: null     # optional: { type: "linear", factor: 1.0 } (future)
  rope_dim: null    # default: head_dim (must be even)

# Classifier head
classifier:
  tie_to_codebook: true          # hard tie to frozen codebook prototypes
  learnable_temperature: true
  use_cosine: false              # false -> distance head; true -> cosine head
  bias_from_code_norm: true      # include -||e||^2 term when distance head
  projector_dim: null            # default: d_model -> head_dim (or d_code)
  ignore_index: -100             # label to ignore in CE loss

# Regularization
dropout: 0.1
attn_dropout: 0.0
norm: "layernorm"                # or "rmsnorm" later

# Initialization
init:
  std: 0.02

# (Optional) external codebook file path (torch .pt tensor, [C, d_code])
codebook:
  path: null
  trainable: false               # keep frozen to preserve decoder semantics


