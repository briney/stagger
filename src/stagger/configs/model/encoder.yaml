# model hyperparameters
d_model: 768
n_heads: 12
n_layers: 12
ffn_mult: 4.0       # expansion factor for SwiGLU
vocab_size: 32      # input AA vocab, e.g., 20 + pad/unk
codebook_size: 4096  # number of structure tokens/classes
pad_id: 1

# rotary embeddings
rope:
  base: 10000
  scaling: null     # optional: { type: "linear", factor: 1.0 } (future)
  rope_dim: null    # default: head_dim (must be even)

# classifier head
classifier:
  tie_to_codebook: true          # hard tie to frozen codebook prototypes
  learnable_temperature: true
  use_cosine: false              # false -> distance head; true -> cosine head
  bias_from_code_norm: true      # include -||e||^2 term when distance head
  projector_dim: null            # default: d_model -> head_dim (or d_code)
  ignore_index: -100             # label to ignore in CE loss

# regularization
dropout: 0.1
attn_dropout: 0.0
norm: "layernorm"                # or "rmsnorm" later

# initialization
init:
  std: 0.02

# (optional) external codebook file path (torch .pt tensor, [C, d_code])
# by default, uses the pretrained GCP-VQVAE base model codebook
codebook:
  path: null
  trainable: false               # keep frozen to preserve decoder semantics


