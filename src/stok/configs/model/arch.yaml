encoder:
  d_model: 768
  n_heads: 12
  n_layers: 12
  ffn_mult: 4.0
  vocab_size: 32
  pad_id: 1
  dropout: 0.1
  attn_dropout: 0.0
  norm: "layernorm"

decoder:
  d_model: 1024
  ffn_mult: 4
  n_layers: 12
  n_heads: 8
  attn_kv_heads: 2
  num_memory_tokens: 0

classifier:
  tie_to_codebook: true
  learnable_temperature: true
  use_cosine: false
  bias_from_code_norm: true
  projector_dim: null
  ignore_index: -100

init:
  std: 0.02

codebook:
  preset: "base"
  path: null
  trainable: false


